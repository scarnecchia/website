[{"content":"\r\rThis recipe was shared with me by my cousin Filippo Novelli. I have translated it from Italian and posted it here for my reference.\nEgg Pasta\rIngredients\r\r\rAmount\rIngredient\r\r\r\r300 g\rflour\r\r3\reggs\r\r\r\r\rDirections\rRoll out dough and cut in the shape of a ravioli\rStuff with ricotta, grated peccorino, and black pepper\rRest for one (1) hour at room temperature\rCook for four (4) minutes in boiling salted water\r\rSeparately prepare the sauce with butter, sage, guanciale, and pepper.\n\r\r","title":"Messer Agnolotto","uri":"/recipes/messer-agnolotto/"},{"content":"\rThis week, both Apple and Google have come under fire for continuing to allow sales of a Saudi government app which will enable men to track and manage the women under their guardianship from their app stores. This app effectively makes it easier for men to monitor and restrict the activities of their female relatives, including constraining their ability to travel freely. At the same time, the humanitarian sector is alarmed by the World Food Programme’s decision to engage the data analytics firm Palantir in a 5-year deal.\nGiuditta che decapita Oloferne, Artemisia Gentileschi, 1620–1621.\n\rA New York Times article last year accused academia of being asleep at the wheel when it comes to technology and ethics. The push back was immediate, with scholars pointing out that Information Science and Science, Technology, and Society (STS) programs have been focused on the effects—positive and negative, intended or not—of technology on society. Going a step further, CU Boulder Information Science professor Casey Fiesler has crowdsourced a list of college courses which teach ethics as part of their science and engineering classes. The problem, Fiesler and others have argued, is that academy was never invited on the road trip and that the disciplines which study the interplay of society and technology are seldom those who train engineers, developers, and tech entrepreneurs.\nI’m sympathetic to this argument and have made it myself in the past. However, tech ethics conversations frequently make a host of assumptions about what ethics is and is not capable of doing. At best, this creates confusion, at worst, it allows ethics to be instrumentalized by those organizations whose behavior is the object of our criticism. As a philosophical discipline ethics is far from monolithic. It is a site of intense disagreement and debate, which makes the question “whose ethics” one of profound importance. Compounding this is the tendency to reduce or misdirect conversations about ethical concerns into discussions about compliance and technocratic policy, which elides the true aim of normative ethics: is this action morally right or wrong.\nPolitics is dead, long live politics\rIn a recent Financial Times Alphachat, the Columbia University historian Adam Tooze pointed out that the Davos crowd lacks a social theory, due to the technocratic assumption that policy has replaced politics. However, this assumption isn’t limited to Davos. Last October, I moderated a panel at the German-American conference at Harvard on the topic of disinformation and Germany’s approach to trying to regulate the problem. At one point, I asked how we regulate something as global as the internet, which spans states and polities with very different polities, some hostile to democracy, while encoding it with a desirable set of values. The pushback was immediate: regulation should be neutral to politics and values.\nThis is hardly unusual: With many conferences panels I’ve attended, participated in, or moderated on topics of technology in the humanitarian sector or disinformation in society, the conversation inevitably raises the dangers at hand while neatly skirting questions of power or responsibility. When it comes to accountability, the default assumption is that frameworks or bloodless regulations which don’t constrain anyone will solve the problem. When conversations about tech ethics are treated this way, they all start to sound a bit like Eddie Izzard’s Church of England routine.\nThe problem with this worldview is that in the absence of politics, it is impossible to contest questions of power and values. The technocratic impulse reduces conversations to those of compliance around neutral topics, such as infrastructure and technology, without honestly examining whether the technology is socially desirable, or raising questions of who benefits by constraining the discourse so narrowly and perpetuating the political economy of technology as it exists.\nConsider that Silicon Valley’s founding ideology is a blend of technological utopianism, libertarian thought, and free-market economics. The merits of this can be critiqued and debated, but its adherents would be justified in arguing that they already have a set of ethics. Critics are bound to be disappointed when this leads to schools and firms teaching hard libertarian ethics (such as Nozick.) Similarly, efforts to teach multiple ethical worldviews will ultimately fall short. If calls for tech ethics which are implicit critiques of the way things are now, then only offering an array of options with some mild editorializing about what is right, the most likely outcome is confirmation bias—and disappointment for proponents whose real hope is that their ideas of what is right will win out.\n\rInfomocracy: The Technology of Biopower\rThe World Food Programme’s decision to enter into a partnership with Palantir invoked the language of corporate efficiency and compliance. Indeed, the tool is to be used for a range of activities aimed at affecting cost-savings, including fraud detection (what that means for the on-the-ground politics of aid is an open question.) Palantir, of course, is not particularly discriminatory in its clients, and its relationship with governments raises some particular risks for the sector, but the problem runs much deeper than the humanitarian sector’s relationship with any one firm.\nIn his History of Sexuality, Michel Foucault laid out the concept of biopower. He argued that the biopolitics of the population and the discipline of the individual human were “two poles of development.” The first focused on the body, its disciplining, its optimization, and its integration into systems of economic efficiency. The second, focused on control over the population, through interventions and regulatory controls. These, he argued, were linked together by “a whole intermediary cluster of relations.”\nThe promise and peril in our modern age are that technology seeks to make legible, manipulable, and commodifiable these clusters of relations in a way the administrative state Foucault wrote about never dreamt of. Perhaps intended with the best of intentions, founded out of California counterculture’s belief that digital utopia was achievable, though always questionable from the perspective of human autonomy, it never accounted for politics and power. Absent that, they’ve become tools of surveillance capitalists and tyrants who seek to assert control and dominance over populations.\n\rKilling Tech Ethics to Save The World\rIn a sidebar conversation during a lengthy conference call, a colleague once remarked that different organizations will have different priorities vis-à-vis technology and that they won’t always be rights and ethics. I was taken aback, but he was not wrong. If tech ethics is applied in other sectors as it is so often in my own—through workshops targeting middle management, structured around design thinking, and driven by a compliance mentality—while organizational leadership invites in firms like Palantir, then we may just be rearranging deck chairs on the Titanic. If this is tech ethics, then tech ethics is a dead-end.\nPerhaps we should let it die.\nReal dilemmas of practical ethics are rare but do exist, perhaps particularly in humanitarian action. Those of the nature of “I’ll be damned I do, and the patient will be damned if I don’t,” such as knowing that a young woman and her fetus will die without a medical procedure, but also knowing that she’ll defer to her husband’s refusal to consent on her behalf—as is culturally appropriate. Too often the dilemmas with technology are not dilemmas at all. They may be framed as such, but there is most often a clear right and wrong answer. The only problem is that the right answer is often not that which preserves the status quo. In a damning indictment of Sheryl Sandberg and Harvard Business School’s ethical compass, business journalist Duff McDonald writes in Vanity Fair:\n\r“[Bowen] McCoy was on a trip to the Himalayas when his expedition encountered a sadhu, or holy man, near death from hypothermia and exposure. Their compassion extended only to clothing the man and leaving him in the sun, before continuing on to the summit. One of McCoy’s group saw a”breakdown between the individual ethic and the group ethic,\" and was gripped by guilt that the climbers had not made absolutely sure that the sadhu made it down the mountain alive. McCoy’s response: “Here we are . . . at the apex of one of the most powerful experiences of our lives. . . . What right does an almost naked pilgrim who chooses the wrong trail have to disrupt our lives?” McCoy later felt guilt over the incident, but his parable nevertheless illustrated the extent to which aspiring managers might justify putting personal accomplishment ahead of collateral damage—including the life of a dying man. The fact that H.B.S. enthusiastically incorporated said parable into its curriculum says far more about the fundamental mindset of the school than almost anything else that has come out of it. The “dilemma” was perfectly in line with the thinking at H.B.S. that an inability to clearly delineate the right choice in business isn’t the fault of the chooser but rather a fundamental characteristic of business, itself.\"\n\rChoosing to host an application which extends a man’s control over a woman in a near-chattel like relationship backed up by the violence of the state is not an ethical dilemma. Allowing anti-Vaccination grifters to target women interested in pregnancy is not a dilemma. Neither is banning porn while allowing white nationalism to thrive, stonewalling a UN investigation into genocide, and investing in the facial recognition technology driving China’s ethnic-cleansing of the Xinjaing region. These are choices reflecting a values system and justified by market access and shareholder returns.\nWhat then, is left, if these are the choices firms make? We must consider our values. Not capital V, McKinsey’s-14-Values, but our personal values, and what we expect from the firms we work for, buy from, and hire. However, markets can only go so far, and it’s unreasonable to expect any constituency of users affecting a firm with two billion monthly users, particularly in an era when protest is almost immediately commodified. Breaking these firms up will only guarantee there is more competition selling the same products. This perpetuates the status quo.\nThe answer may be more radical still: do we believe that these choices are compatible with human rights and human autonomy? If not, do firms have a right to make them? In The Network Society, Manuel Castells writes, “[u]ntil we rebuild, both from the bottom up and from the top down, our institutions of governance and democracy, we will not be able to stand up to the fundamental challenges that we are facing.” Perhaps then, it is our responsibility to begin rebuilding, and rebuilding begins tearing down the rot. Certainly, Silicon Valley has lost any credible claim to being able to self-regulate, as do those who buy into their Faustian bargain. Therefor, it is time to impose an uncompromising set of values on technology firms and the capital behind them.\nThis is not a call for popular, populist values: those too often reflect the id of a society. But if there is anything worth saving in liberal internationalism, if won’t be found in bloodless transactional technocracy, without conviction or politics, bound to the ideology of unregulated markets and efficiency. This serves the interests of the status quo over everything else, and more often then not, sides with essentialist, far-right, or authoritarian world-views when confronted with calls for change. Rather, it is a call to embrace the problem as one of politics, and to take a stand.\n\r","title":"Tech Ethics Won't Save Us","uri":"/post/2019/02/19/tech-ethics-won-t-save-us/"},{"content":"\r\rAn overextended superpower is brought low in an era of ideological polarization, set against the backdrop of a widely adopted new technology which has radically transformed people’s relationship with information. Over 10 percent of the population dies in the subsequent conflicts. This isn’t a dark portent of a potential future. It’s a lesson from our past about the dangers that can arise when technology and politics intersect.\nThomas Cole, The Course of Empire—Destruction, 1836 via Wikimedia Commons\n\rIn his history of the modern West, the late historian Jacques Barzun asserted that the widespread adoption of the printing press gave Luther’s Reformation the traction that earlier efforts at reform lacked. The resulting combination of religious fervor and political competition created a perfect storm which allowed opportunistic princes to fracture Charles V’s holdings and tip Europe into a century of turmoil.\nToday, we are at moment of rapid technological change. Digital technologies are effecting our societies and politics in unanticipated ways, and the institutions which safeguard our society are just beginning to grapple with the implications. Last month, in London, the International Committee of the Red Cross (ICRC) hosted a symposium on Digital Risk in Situations of Armed Conflict. This symposium aimed to develop a deeper understanding of the risks posed by digital technology to civilians caught up in conflict. One of its three tracks was the weaponization of information with a focus on disinformation, hate speech, and influence operations.\nUnfortunately, the popular view is still of interference as discrete events, rather than a systemic problem that challenges the very future of the international system which humanitarianism operates. In the popular media, the disinformation conversation is primarily focused on singular cases, whether it is Russian interference in electoral politics in the US, the role of Facebook in the spread of hate speech in Myanmar’s Rohingya crisis, or anti-migrant violence in Germany.\nHowever, viewing these individually misses the forest for the trees. Influence operations are a new twist on an old conflict—the struggle for international power. Policymakers—particularly those who are the guardians of International Law—must understand information operations and disinformation in this context. To not do so risks creating what Data4Democracy’s Renee DiResta recently called a “Digital Maginot Line”, that is, policies designed to meet past challenges instead of the next problem.\nStates and other international political actors (think ISIS, private citizens, and even corporations) use influence operations to gain political advantage or disrupt an opponents ability to act. This is best illustrated in two examples relevant to humanitarian action and the protection of civilians: the conflict in Syria and migration in the Mediterranean.\nSyria\rTo read about Syria on Twitter is to step into a conspiratorial world where chemical weapons attacks are rebel false flags, the White Helmets are simultaneously ISIS terrorists and puppets of the West, and the entire human rights and humanitarian world has conspired with Western governments to promote regime change. This conspiratorial ecosystem weaves across blogs, social media, and traditional—albeit state-run—media.\nRecent research published by Dr. Kate Starbird at the University of Washington (Disclosure: I am a co-author) reveals a transnational, information space where a handful of “independent” authors produce content aligned with Syrian, Russian, and Iranian messaging. This content is then repackaged across far-right and left-wing media, and promoted by the state-run media outlets.\nThese conspiracy theories haven’t remained the province of fringe online communities. They have been repeated by mainstream actors like a US congresswoman, a Virginia state senator, and printed by mainstream outlets such as Newsweek. In all of these cases, the narratives have questioned the veracity of evidence of human rights abuses and war crimes and echoed Russian officials—despite credible reporting that Syrian forces are responsible for nearly all chemical weapon attacks against civilians. Nor is this problem isolated to the United States. In Britain, a Labour MP recently praised one of the chief authors of these theories, and an activist group with close ties to Labour have lent their platform to speakers repeating these anti-White Helmet narratives. States deny atrocities because it works. They aim to obfuscate reality enough to prevent decisive action by their opponents. Similarly, influence campaigns, as a mode of propaganda, are not intended to persuade but are instead a means to disrupt official narratives, to undermine a society’s ability to act collectively towards a common goal. Further research by the University of Washington team shows that the disinformation phenomenon is more complicated than the simple propaganda metaphor would suggest, nor is it merely the domain of bots and troll armies. Instead, it is a space contested by diverse groups of actors which more closely resemble online activists—and state and other political actors are often embedded in these online communities. The resulting combination of sincere, organic activism, and cultivation by state actors makes it very difficult to disentangle what is disinformation and what is legitimate political speech.\n\rMigration\rThis speaks to the power of these technologies to diffuse narratives into the broader body politic of states. And that raises the critical question: where do state-sponsored influence campaigns end and activism and politics begin? While not always directly related to any given conflict, the politics of migration in Europe illustrate how information operations are a tool of international politics, and vulnerable civilians are the collateral damage.\nRussian broadcaster Sputnik stands accused of radicalizing the immigration debate on Italian social media during 2018 elections, pushing “questionable sources, biased experts and sensationalist headlines.” The EU finds that state-run influence operations constitute a significant source of disinformation around migrants in Europe and are deliberately used to fuel the rise of anti-migrant political parties. More recently, far-right YouTube personalities and anti-migration activists have been secretly filming—and allegedly misrepresenting—the activities of NGOs working with refugees in Greece, footage Russian state media are happy to opportunistically promote.\nThis has real-world consequences. States across Europe have begun impounding and de-flagging of NGO rescue ships, the criminalizing humanitarian activities, and are using prosecution to deter humanitarian aid. The consequences are worse—and often deadly—for migrants. While migration rates have dropped significantly in 2018, the Italian Institute for International Political Studies finds that death rates in among migrants making the crossing in September 2018 rose to 19%—and suggested that this was squarely the fault of the Italian government for deterring rescues at sea. Refugees have the right to protection and asylum. Courts have found that returning rescued migrants to Libya would violate their fundamental rights.\n\rTechnologically Mediated Confessionalization\rTechnology’s transformative effects on civil society have been lauded for decades, but only recently has the attention of scholars turned to the ability of illiberal actors to use these tools. This phenomenon is likely made worse by the fact that social media is qualitatively different from other media. It allows people and groups to forge new networks and identities, and to share information more rapidly. While not wholly the cause of populist politics and propaganda, these platforms have amplified it in ways that neither tech companies nor democracies anticipated.\nTechnology companies will not be our saviors. Facebook has been condemned by the UN for the inadequacy of its response to hate speech in Myanmar. To start, it’s wholly unclear that it understands how to handle the problem. But it’s also fundamentally at odds with it’s core obligations. Why should Facebook remove false, misleading, or dangerous content of its own volition? Facebook has a fiduciary obligation to its shareholders, not to human rights or democratic norms. Assuming tech companies share these values fundamentally misunderstands the nature and the purpose of the firm.\nDrawing lessons from the past is never simple and Barzun did not hold the printing press directly responsible for Europe’s religious wars. But the press drastically altered how 16th century Europeans related to information and ideas, helping foster new identities and transnational networks along religious lines. This process of confessionalization reached across borders and interacted with existing vulnerabilities in the era’s political system, creating room for opportunistic actors to increase their own power, and ultimately reorder the international system through conflict.\nSocial media is a new tool in a conflict as old as civilization: the competition for international power. States use these technologies to capably manipulate activists and electorates, and often vulnerable people pay the price. Global civil society and policymakers must never assume that laws safeguarding the rights, dignity, and autonomy of humanity are durable features of history.\nIndeed, many of the actors currently engaging in influence operations—both state and non-state—are not sympathetic to humanitarian action in its current form. Civil society and humanitarian actors must realize that the battle to protect civilians is being fought in the electorates and policy communities of the West as much as it is on the streets of Idlib. They must realize that they too are political actors with a responsibility to confront powers which seek to use these tools to undermine systemic protections for the most vulnerable.\n\r","title":"International Information Power Politics","uri":"/post/2019/01/17/international-information-power-politics/"},{"content":"\r\rJohn Singer Sargent: Orestes Pursued by the Furies (1921) via Wikimedia Commons\n\rFor the first time in history, war and the attendant human suffering are occurring in societies connected to mobile internet–and subsequently entering the public consciousness in new ways. Aspects of war and conflict that were once near-invisible to those outside the war zone are now visible world-wide on social media platforms. People far away from the battlefield can now interact with and impact conflict in unprecedented and unexpected ways. The Internet has altered our public consciousness of war, in ways that we do not adequately understand.\nHistorically, information technology has been seen as benefiting human rights movements, civil society, and promoting democracy. But this optimistic view of technology masks a dark side, one which is not purely the domain of domestic politics. These platforms, and the misinformation and disinformation that are spread upon them, appear to play an increasing role in conflict and humanitarian crises.\nWhat are misinformation and disinformation?\rThe term “fake news” implies pure falsehoods, and subsequently fails to capture the breadth of what misinformation and disinformation are. Often, “fake news” is disinformation, what scholars at the Berkman Klein Center at Harvard Law School define as “the purposeful construction of true or partly true bits of information into a message that is, at its core, misleading.” This is distinct from misinformation, which is generally false information that is not deliberately or maliciously spread, though it may have harmful effects. This post will discuss both disinformation and misinformation, and argues that both phenomenon—along with outright lies—should concern humanitarians.\n\rEbola\rDuring the Ebola crisis in West Africa, several returning US healthcare workers contracted the disease, prompting a public scare about the potential for an outbreak here. A paper by the MIT Civic Media Centre in 2017 established that the fourth- most cited media source regarding the Ebola crisis and the subsequent US controversy was Twitter, and that the discourse on this platform was largely focused on the exceedingly small risk of a US outbreak rather than on the very real Ebola crisis in West Africa.\nThe authors of the MIT paper concluded that while scientific sources rarely discussed quarantines and travel bans, the Twitter discourse prioritized these extreme measures. They suggest that political media and policy-makers may have been influenced more by the less-informed Twitter discourse than they were by the less-sensational but more scientifically accurate scientific discussion, and that international policy responses subsequently reflected these more extreme sentiments, ultimately diverting effective aid and leading states to violate international law.\n\rMyanmar\rBetween 2011 and 2016, the number of people connected to the internet in Myanmar grew from around 10000 people to over 35 million—70 percent of the population. Much of this access was driven by Facebook’s partnership with Myanmar’s state telecom provider. As of 2017, 30 million people in Myanmar were connected to the Internet through Facebook’s Free Basics.\nThis immense rise in connectivity seems to have come at a cost: the New York Times reports that hate speech and rumors against Myanmar’s Rohingya minority group have gone viral. Hate speech and disinformation against the Rohingya has been spread by political figures, religious extremists, and everyday people. The U.N.’s Independent Fact-Finding Mission on Myanmar recently asserted that social media played a critical role in the spread of hate speech, and that the role of Facebook in public and political life in Myanmar has made it into an effective channel for disinformation.\n\rSyria\rMyanmar is far from the only recent humanitarian crisis where social media has played a role. The Carter Center’s documentation of the conflict in Syria is based in part on social media data. Human rights group Bellingcat uses online information and social media postings to gather evidence of atrocities. These online sources are valuable in non-permissive environments like Syria, where researchers cannot safely travel to gather first-hand information themselves. But there is a dark side to these social media accounts of the Syrian conflict. Multiple traditional media accounts report the existence of a sustained, online disinformation campaign that is being waged against the Syrian Civil Defence volunteer first response organization, also known as the White Helmets. The Guardian pointed out in a December 2017 report that Syrian and Russian state media are participating in this campaign. This campaign appears to have two goals: eroding public sympathy for the White Helmets, and discrediting them as a key source of evidence of war crimes committed by belligerents in Syria. This may, in turn, play a role in undermining humanitarian access to opposition held areas in Syria, and allow warring parties to commit atrocities with impunity.\nAccess Denial\rSince the beginning of the Syrian conflict, humanitarian actors have alleged that the government has attempted to limit humanitarian access to opposition held areas with bureaucratic red tape and lack of protection. A 2018 report by the UN Independent Commission on the Syrian Arab Republic goes further, reporting that “humanitarian aid has been instrumentalized as a weapon of war.” The UN has failed to implement proposed reforms in response to this situation, due to political pressure from Damascus.\nAs a result of this politicization of aid, international relief operations have responded by forging unofficial partnerships with local NGOs, and by quietly working across opposition lines without the permission of the Syrian government. Many of these local NGOs, like the White Helmets, were formed out of pre-war networks of activists or healthcare workers. Many of them, like the White Helmets, have been deliberately targeted by the Syrian government and their allies.\nMore so than any other local response organization in Syria, the White Helmets have captured public imagination in the West, including an Oscar-winning film. Not all of this attention has been positive. The White Helmets are now subject to sustained misinformation and disinformation campaign which portrays them as terrorists who can legitimately be targeted as combatants. Although it is tempting to dismiss these campaigns as the inconsequential work of conspiracy theorists and state media, their influence is spreading far beyond social media. Promoters of these anti-White Helmets theories have been cited at the UN, credible media outlets have published their claims, and even some well-meaning activist groups appear to be getting swept up in supporting them. That it is not clear where state manipulation of the discourse ends and genuine mistrust of Western intentions begins is itself a problem for the humanitarian community and human rights NGOs, which may find these debates playing out internally, as warring parties attempt to manipulate aid by invoking the Humanitarian Principles and promoting competing narratives, all while declaring civilians legitimate targets in defiance of ICRC guidance.\n\rGetting away with (Mass) Murder\rIn late October, the United Nations and the Organization for the Prohibition of Chemical Weapons (OPCW) released a report pointing the finger at the Syrian government for using deadly sarin gas on civilians in the village of Khan Sheikhoun. The report relied upon scientifically valid evidence, including samples of blood from the victims and soil from the site — some collected by local and diaspora response groups. Despite this evidence, the Syrian government has denied complicity in the attack from the very beginning and has offered conspiratorial alternative explanations for the deaths. These alternative explanations for the attack have been picked up by anti-White Helmets activists and warring party state media alike—in attempts to undermine both the Helmets and the OPCW report by linking the latter to the former and declaring them terrorist sympathizers or western propaganda.\nHarvard scholar Kate Cronin-Furman suggests that the Syrian government’s atrocity denial may be modeled on a strategy established by Sri Lanka in its war against Tamil rebels. She writes that the Syrian government, as the Sri Lankan government did, aggressively disputes evidence and reports emerging from the conflict as propaganda, and shifts blame to rebel forces for the crimes it cannot feasibly deny. Work by Oxford’s Computational Propaganda Research Project points to social media strategies which manufacture the illusion of consensus and “democratize propaganda”—making it easy for anyone with an account to amplify false information, even if they do not actually intend to do so. Thanks to social media, warring parties in Syria appear to have put the this strategy of denial and blame-shifting on steroids.\n\r\rWhy is this different from other forms of media?\rAre rumors and propaganda spread via the Internet really that different from rumors and propaganda spread via the radio or print media? Are these platforms really any different than broadcast media? After all, Radio Télévision Libre des Mille Collines is often cited as a contributor to the 1994 Rwandan Genocide. The research around whether 2G mobile phone access increases the likelihood of conflict is also inconclusive—some studies suggest it does, while others draw the opposite conclusion. But information and disinformation spread differently through Social media than more traditional platforms—potentially making the latter more dangerous.\nSocial media platforms and the Internet give disinformation a power it didn’t have though traditional media. The basic network structure of these social media sites allows information to spread much more rapidly and widely than traditional media by increasing the density and immediacy of what is known in network sociology as “weak ties.” These ties are the acquaintances in a social group—not the person that you’d invite out to a night with friends, but who you would only call for a specific reason—such as finding a job. These ties build bridges social groups, and are the most common source of new information in a given group. Increasing these weak ties, along with the peer-to-peer content sharing model of social media, and our preference to trust information based on who shared it, spreads information and disinformation in ways which are very different than broadcast medium such as radio and television\nPolling in Myanmar from 2017 reveals that 73% of Facebook users in Myanmar use it for reading the news, and 60% report seeing posts about ethnic or religious conflict within the last week. These monetized platforms now mediate much of our social and public lives, and they are driven by algorithms designed to maintain our attention. The emergence of these algorithms as mediators of content within these networks may have additional effects—effects that shape not only how we interact with information but also how determine what is worth sharing. University of North Carolina sociologist Zeynep Tufeki notes that Youtube has determined that the best way to keep people engaged is to promote increasingly extreme content into their feeds, using its proprietary algorithms. Facebook’s algorithmic recommendation engine — along with its Groups feature—are also thought to play an important role in exposing people to extreme content, potentially radicalizing them.\nIf the recent Cambridge Analytica scandal has shown us anything, it’s that tools designed for capturing and selling our attention can be used to political ends and create political incentives in their own right. While conclusive evidence is not yet available, it stands to reason that the use and abuse of these platforms for political ends in societies with latent (or overt) ethnic or political tensions can inflame those tensions.\nIn Myanmar, this may increase the likelihood of tensions spilling over into ethnic violence and genocide. In Syria, they may be used to politicize aid and allow those guilty of alleged war crimes walk free. Even where intent doesn’t exist, the lessons of Ebola suggest that the role of these platforms in influencing public sentiment and policy makers choices regarding aid operations should not be underestimated. And these are far from the only examples: the humanitarian community needs to be asking itself what the use of anti-migrant disinformation in elections means for states’ willingness to uphold their obligations under the Refugee Convention, as well as other international conventions and treaties. Does this herald the end of multi-lateral humanitarianism?\nWhile the problems of humanitarian access and aid cannot and should not be boiled down to a single issue, the daily drumbeat of news on how social media is shaping our societies and politics should not be ignored by the humanitarian community. After all, humanitarianism exists in a political world. If these platforms have the potential to undermine the very norms which construct our existence as a sector, the norms that protect both aid workers and civilians, and effect the decisions of policy makers towards aid, then the humanitarian community desperately needs a strategy address the new media world we live in today.\n\r","title":"Humanitarianism’s other technology problem","uri":"/post/2018/04/02/humanitarianism-s-other-technology-problem/"},{"content":"","title":"About","uri":"/about/"}]
